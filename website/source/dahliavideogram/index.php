<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
    <title>Shasta Exchange</title>
    <style type="text/css">
    * {
      margin: 0px 0px 0px 0px;
      padding: 0px 0px 0px 0px;
    }

    body {
     background-color: #3D6198;
    }

    #business_name {
      font-size: 5.11em;
      text-align: center;
      padding: 0.5em 0.5em 0 0.5em;
      margin: 0em 0.5em 0 0.5em;
      font-family: PlayFairFont;
      text-shadow: 0 0 2px #000000, 0 0 2px #000000, 0 0 5px #000000, 0 0 10px #000000; 0 0 10px #000000; 0 0 10px #000000;
      color: #f64f4f;
    }
  
   
    div.header_quick_links {
      text-align: center;
      width: 99.999999%;
      padding-top: 2.5em;
      padding-bottom: 2.5em
    }

    #business_elevator_pitch {
      font-size: 2.4em;
      text-align: center;
      font-family: PlayFairFont;
      padding: 0 0.5em 0.5em 0.5em;
      margin: 0.5em 0.5em 0.5em 0.5em;
      text-shadow: 0 0 2px #7d1e3e, 0 0 2px #7d1e3e, 0 0 3px #7d1e3e, 0 0 5px #000000, 0 0 5px #000000; 0 0 5px #000000;
      color: #f64f4f;
      font-weight: 900;
    }

    #logo_business_name {
     width: 99.999999%;
     background: url("/demo_background.jpeg");
     background-repeat: no-repeat;
     background-position: center 120px;
     padding-bottom: 200px;
     border-bottom: 3px solid #f64f4f;
    }

    @font-face {
     font-family: PlayFairFont;
     src: url("/externally_provided/fonts/PlayFair_Display/PlayfairDisplaySC-Regular.otf");
    }

    @font-face {
     font-family: MochiPopOne;
     src: url("/externally_provided/fonts/mochiypop/fonts/ttf/MochiyPopOne-Regular.tff");
    }

    .easy_page_header {
     text-align: center;
     
     padding: 1em;
     margin: 0 2em 1em 2em;
     border-radius: 10px;	
     background: #008CBA;
     box-shadow: 3px 3px 5px #000000;
    }

    a.shasta_exchange_navigation:link {
     text-align: center;
     font-size: 3.5em;
     text-decoration: none;
     
    }

    a.shasta_exchange_navigation:visited {
     font-family: MochiPopOne;
     color: #ffffff;
     text-shadow: 0 0 2px #7d1e3e, 0 0 2px #7d1e3e, 0 0 3px #7d1e3e;
     text-decoration: none;
    }

    .menu_header {
     text-align: center;
     font-size: 3.5em;
     font-family: PlayFairFont;
     text-shadow: 0 0 2px #7d1e3e, 0 0 2px #7d1e3e, 0 0 3px #7d1e3e;
      color: #f64f4f;
      font-weight: 900;
    }
	
    .blog_introduction {
     border-radius: 10px;
     background: #008CBA;
     border: 3px solid #000000;
     margin: 0 0.5em 0.5em 0.5em;
     font-size: 3.5em;
     color: #ffffff;
     padding: 1em;
    }
    </style>
  </head>
  <body>
    <div id="logo_business_name">
      <h1 id="business_name">Shasta Exchange</h1>
      <h2 id="business_elevator_pitch">Digital based printed media</h2>
    </div>
    
   
    <div class="menu_header">
     Navigate
    </div>
        <div class="easy_page_header">
     <a href="/" class="shasta_exchange_navigation">Welcome</a>
    </div> 
    <div class="easy_page_header">
     <a href="/blog/index.php" class="shasta_exchange_navigation">Blog</a>
    </div> 
 
    <div class="easy_page_header">
     <a href="" class="shasta_exchange_navigation">Dahlia Video Gram</a>
    </div>
    <div style="margin: 3em;">&nbsp;</div>
    <div class="menu_header">
     Dahlia Video Gram Presentation
    </div>
    <div class="blog_introduction">
    &nbsp;&nbsp;&nbsp;&nbsp;Dahlia Video Gram technology is a prescribed method for transporting video and audio data in a manner that complete audio is delivered per requested segment of playback while the video playback will have different means of quality based on speed of delivery limited by the transportation method(network, tcp, udp, raw sockets). <br/><br/>
     Video pixels are choosen by a predetermined formula and then streamed from lowest quality, medium quality, and high quality. To be clear the lowest quality of the video is streamed first for also a predetermined segment, such as one minute is buffered. Then more pixel data is streamed for those same one minute of the video file, then more pixel data is streamed for those same one minute of the video file. this allows for almost immediate playback with the downside of low quality playing for the first few seconds, while the medium quality begins to play as it is loaded and so on with the high quality.  <br/><br/>
     The purpose is to precent fatigue in the workplace and or during times of personal entertainment. A most specific use would be for users browsing an encyclopedia on a slow network; Users would be forced to wait for a full and complete segment of audio to load (from five seconds to a minute) allowing for the user to know if that is something they are interested in. If they are not interested they dont have to wait for the video(low quality portion) to load, then can exit the page or move along. Granted if the user is interested then the buffering mechism will load the low quality portion allowing them to "recognize" what is happening, the user is then able to select which autoplay option they prefer or they can select high quality(or medium quality only) forcing the play back  to pause the video and audio until the select only wuality is full buffered for a selected segment of five seconds to a minute. <br/><br/>
     The other quality option is variable network medium quality and variable network high quality. this will only begin playback when medium quality is available while delivering highquality pixel data. providing an experience that feels like your watching 720p most of the time however the playback it self will instead of becoming paused to load 720p will play the already loaded 520p data.  <br/><br/>
     As you may have guessed this is extremely critical for live streaming and bi directional communication for poor communities and or during environmental disasters of interrupted networking conditions.
    
    </div>
    
    
    <div style="margin: 3em;">&nbsp;</div>
    <div class="menu_header">
     Low Quality Video Streaming
    </div>
    <div class="blog_introduction">
      &nbsp;&nbsp;&nbsp;&nbsp;Low quality frames are sent over the network, which is defined as every other pixel per column and row is delivered; This is depicted within the following photo.
      <img src="/dahliavideogram/image/exact_data_sent_from_service/low_quality_or_phase_one_sent_by_server.jpeg" style="width:90%;" />
      
      <br/><br/>
      
      Due to pixels being so small this tiny amount of data the user would not be able perceive that there is anything to be viewed. I would like to note that although the data is tiny and the pixels are too small to see within their own positions spaced out that it's actually been found its enough to recognize objects and match those objects with a imagined model derived from highquality and high fidelity audio streams;   <br/><br/>Therefore, the pixels are stretched to allow taking advtange of this opportunity object recognition(using the human mind, not artificial intelligence). This stretching makes objects appeared blurred when the source video is 520p or less and the when the source video is HD(720p or 1080p) the low quality video feels like a 520p video with low network delivery times that are similar to 320p raw rgb video network deivery times. This stretching is depicted within the following image.
      
      <img src="/dahliavideogram/image/demonstrated_client_view/phase_one_client_view.jpeg" style="width:90%;" />
    </div>
    
    
    <div style="margin:3em;"></div> 
    <div style="margin:0.5em;text-align:center; color:#ffffff; font-size:2.5em;">Page created by Shane Bryan Betz</div>
    <div style="margin:6em;"></div>
   </body>
  </html>

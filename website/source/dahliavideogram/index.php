<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
    <title>Shasta Exchange</title>
    <style type="text/css">
    * {
      margin: 0px 0px 0px 0px;
      padding: 0px 0px 0px 0px;
    }

    body {
     background-color: #3D6198;
    }

    #business_name {
      font-size: 5.11em;
      text-align: center;
      padding: 0.5em 0.5em 0 0.5em;
      margin: 0em 0.5em 0 0.5em;
      font-family: PlayFairFont;
      text-shadow: 0 0 2px #000000, 0 0 2px #000000, 0 0 5px #000000, 0 0 10px #000000; 0 0 10px #000000; 0 0 10px #000000;
      color: #f64f4f;
    }
  
   
    div.header_quick_links {
      text-align: center;
      width: 99.999999%;
      padding-top: 2.5em;
      padding-bottom: 2.5em
    }

    #business_elevator_pitch {
      font-size: 2.4em;
      text-align: center;
      font-family: PlayFairFont;
      padding: 0 0.5em 0.5em 0.5em;
      margin: 0.5em 0.5em 0.5em 0.5em;
      text-shadow: 0 0 2px #7d1e3e, 0 0 2px #7d1e3e, 0 0 3px #7d1e3e, 0 0 5px #000000, 0 0 5px #000000; 0 0 5px #000000;
      color: #f64f4f;
      font-weight: 900;
    }

    #logo_business_name {
     width: 99.999999%;
     background: url("/demo_background.jpeg");
     background-repeat: no-repeat;
     background-position: center 120px;
     padding-bottom: 200px;
     border-bottom: 3px solid #f64f4f;
    }

    @font-face {
     font-family: PlayFairFont;
     src: url("/externally_provided/fonts/PlayFair_Display/PlayfairDisplaySC-Regular.otf");
    }

    @font-face {
     font-family: MochiPopOne;
     src: url("/externally_provided/fonts/mochiypop/fonts/ttf/MochiyPopOne-Regular.tff");
    }

    .easy_page_header {
     text-align: center;
     
     padding: 1em;
     margin: 0 2em 1em 2em;
     border-radius: 10px;	
     background: #008CBA;
     box-shadow: 3px 3px 5px #000000;
    }

    a.shasta_exchange_navigation:link {
     text-align: center;
     font-size: 3.5em;
     text-decoration: none;
     
    }

    a.shasta_exchange_navigation:visited {
     font-family: MochiPopOne;
     color: #ffffff;
     text-shadow: 0 0 2px #7d1e3e, 0 0 2px #7d1e3e, 0 0 3px #7d1e3e;
     text-decoration: none;
    }

    .menu_header {
     text-align: center;
     font-size: 3.5em;
     font-family: PlayFairFont;
     text-shadow: 0 0 2px #7d1e3e, 0 0 2px #7d1e3e, 0 0 3px #7d1e3e;
      color: #f64f4f;
      font-weight: 900;
    }
	
    .blog_introduction {
     border-radius: 10px;
     background: #008CBA;
     border: 3px solid #000000;
     margin: 0 0.5em 0.5em 0.5em;
     font-size: 3.5em;
     color: #ffffff;
     padding: 1em;
    }
    </style>
  </head>
  <body>
    <div id="logo_business_name">
      <h1 id="business_name">Shasta Exchange</h1>
      <h2 id="business_elevator_pitch">Digital based printed media</h2>
    </div>
    
   
    <div class="menu_header">
     Navigate
    </div>
        <div class="easy_page_header">
     <a href="/" class="shasta_exchange_navigation">Welcome</a>
    </div> 
    <div class="easy_page_header">
     <a href="/blog/index.php" class="shasta_exchange_navigation">Blog</a>
    </div> 
 
    <div class="easy_page_header">
     <a href="" class="shasta_exchange_navigation">Dahlia Video Gram</a>
    </div>
    <div style="margin: 3em;">&nbsp;</div>
    <div class="menu_header">
     Dahlia Video Gram Presentation
    </div>
    <div class="blog_introduction">
    &nbsp;&nbsp;&nbsp;&nbsp;Dahlia Video Gram technology is a prescribed method for transporting video and audio data in a manner that complete audio is delivered per requested segment of playback while the video playback will have different means of quality based on speed of delivery limited by the transportation method(network, tcp, udp, raw sockets). <br/><br/>
      &nbsp;&nbsp;&nbsp;&nbsp;Video pixels are choosen by a predetermined formula and then streamed from lowest quality, medium quality, and high quality. To be clear the lowest quality of the video is streamed first for also a predetermined segment, such as one minute is buffered. Then more pixel data is streamed for those same one minute of the video file, then more pixel data is streamed for those same one minute of the video file. this allows for almost immediate playback with the downside of low quality playing for the first few seconds, while the medium quality begins to play as it is loaded and so on with the high quality. 
      <br/><br/>
      &nbsp;&nbsp;&nbsp;&nbsp;The purpose is to precent fatigue in the workplace and or during times of personal entertainment. A most specific use would be for users browsing an encyclopedia on a slow network; Users would be forced to wait for a full and complete segment of audio to load (from five seconds to a minute) allowing for the user to know if that is something they are interested in. If they are not interested they dont have to wait for the video(low quality portion) to load, then can exit the page or move along. Granted if the user is interested then the buffering mechism will load the low quality portion allowing them to "recognize" what is happening, the user is then able to select which autoplay option they prefer or they can select high quality(or medium quality only) forcing the play back  to pause the video and audio until the select only wuality is full buffered for a selected segment of five seconds to a minute. 
     <br/><br/>
      &nbsp;&nbsp;&nbsp;&nbsp;The other quality option is variable network medium quality and variable network high quality. this will only begin playback when medium quality is available while delivering highquality pixel data. providing an experience that feels like your watching 720p most of the time however the playback it self will instead of becoming paused to load 720p will play the already loaded 520p data.  <br/><br/>
      &nbsp;&nbsp;&nbsp;&nbsp;As you may have guessed this is extremely critical for live streaming and bi directional communication for poor communities and or during environmental disasters of interrupted networking conditions.
    
    </div>
    
    
    <div style="margin: 3em;">&nbsp;</div>
    <div class="menu_header">
     Low Quality Video Streaming
    </div>
    <div class="blog_introduction">
      &nbsp;&nbsp;&nbsp;&nbsp;Low quality frames are sent over the network, which is defined as every other pixel per column and row is delivered; This is depicted within the following photo.
      <img src="/dahliavideogram/image/exact_data_sent_from_service/low_quality_or_phase_one_sent_by_server.jpeg" style="width:90%;" />
      
      <br/><br/>
      
       &nbsp;&nbsp;&nbsp;&nbsp;Due to pixels being so small this tiny amount of data the user would not be able perceive that there is anything to be viewed. I would like to note that although the data is tiny and the pixels are too small to see within their own positions spaced out that it's actually been found its enough to recognize objects and match those objects with a imagined model derived from highquality and high fidelity audio streams;  
       <br/><br/>
       &nbsp;&nbsp;&nbsp;&nbsp;Therefore, the pixels are stretched to allow taking advtange of this opportunity object recognition(using the human mind, not artificial intelligence). This stretching makes objects appeared blurred when the source video is 520p or less and the when the source video is HD(720p or 1080p) the low quality video feels like a 520p video with low network delivery times that are similar to 320p raw rgb video network deivery times. This stretching is depicted within the following image.
      
      <img src="/dahliavideogram/image/demonstrated_client_view/phase_one_client_view.jpeg" style="width:90%;" />
    </div>
    
    
    <div style="margin: 3em;">&nbsp;</div>
    <div class="menu_header">
     Medium Quality Video Streaming
    </div>
    <div class="blog_introduction">
      &nbsp;&nbsp;&nbsp;&nbsp;Medium quality frames are sent over the network, which is defined as every pixel per even column of every row is delivered; This is depicted within the following photo.
      <img src="/dahliavideogram/image/exact_data_sent_from_service/medium_quality_or_phase_one_sent_by_server.jpeg" style="width:90%;" />
      
      <br/><br/>  <br/><br/>
      
       &nbsp;&nbsp;&nbsp;&nbsp;Let us say that perhaps for the intentions of conveying and understanding is that the dahlia video gram transmitted low quality and medium quality as one group of data or might also be described as sending one stream segment; <br/><br/>This is something that is never done and should not be done as this increases buffer time or more precisely increases the amount of time the viewer would have to wait for the video begin playing with otherwise low quality and high fidelity video playing; However let us say that this did happen, it would be as depicted within the following photo.
      
       <img src="/dahliavideogram/image/demonstrated_client_view/phantom_combined_low_and_medium_quality_photo.jpeg" style="width:90%;" />
       
       
          <br/><br/>     <br/><br/>
          
           &nbsp;&nbsp;&nbsp;&nbsp;The client will view medium quality as shown(continued below) within the demonstrated photo when the viewer decides to play the video and the low quality frames have buffered and so have the medium quality frames have buffered. 
          
           <img src="/dahliavideogram/image/demonstrated_client_view/phase_two_client_view.jpeg" style="width:90%;" />
           
             <br/><br/> 
             
              &nbsp;&nbsp;&nbsp;&nbsp;The above photo is a demonstration on the stretching of the pixels into the empty spaces occurs, however the production version of this technology will utilize a blending method that will take the surrounding colors of the empty space and mix those colors to fill the empty spaces instead. The following photo shows the output of pixels after they have been stretched. As you can see this looks almost exactly like the source photo(shown in the high quality section below).
           
            <img src="/dahliavideogram/image/demonstrated_client_view/phase_two_client_view_pixel_layout.jpeg" style="width:90%;" />
          
           <br/><br/>     <br/><br/>
          
           &nbsp;&nbsp;&nbsp;&nbsp;Using a bi directional communication the states of the  client can be alerted to the service allowing the service to prioritize continuous low quality frames or the alternative transmiting low quality and medium qualitu segments(while the video is paused for example) this then can allow for the network to buffer high qualitu frames that are about to play while the viewer is enjoying the buffered low and medium combined framed data. 
          <br/><br/>
           &nbsp;&nbsp;&nbsp;&nbsp;Remember this mode of video viewing is intended to relieve frustrations of waiting and a supposed precomputed means of working with unstable networks and or low bandwidth situations. Another way to put it is dial up users would be able to enjoy motion pictures with objectively the only frowned upon operation of the system being low quality, which is expected however not being able ro watch a video for an entire day is not expected by dialup users for example.
       
     </div>
     
     
    <div style="margin: 3em;">&nbsp;</div>
    <div class="menu_header">
     High Quality Video Streaming
    </div>
    <div class="blog_introduction">
     &nbsp;&nbsp;&nbsp;&nbsp;High quality frames are sent over the network, which is defined as every odd column and even row; This is depicted within the following photo.
      <img src="/dahliavideogram/image/exact_data_sent_from_service/high_quality_or_phase_three.jpeg" style="width:90%;" />
     
      <br/><br/>  
      
      The perspective of the client that the user does not see would be like the following, low quality is received, then medium quality is received, then high quality is received.<br/>
        <img src="/dahliavideogram/image/exact_data_sent_from_service/low_quality_or_phase_one_sent_by_server.jpeg" style="width:90%;" />
        <br/>
          <img src="/dahliavideogram/image/exact_data_sent_from_service/medium_quality_or_phase_one_sent_by_server.jpeg" style="width:90%;" />
          <br/>
           <img src="/dahliavideogram/image/exact_data_sent_from_service/high_quality_or_phase_three.jpeg" style="width:90%;" />
     <br/>
     then the image partials are fit together exactly to pixel precision to produce the source quality video file, which is considered the least delusional information recognition to the customers experience.
     <br/>
       <img src="/dahliavideogram/image/demonstrated_client_view/phase_three_view.jpeg" style="width:90%;" />
    </div>
    
    
    <div style="margin: 3em;">&nbsp;</div>
    <div class="menu_header">
     Post demonstration report
    </div>
    <div class="blog_introduction">
       &nbsp;&nbsp;&nbsp;&nbsp;The main theme with dahlia video gram is to not use compression schemes that reconstruct data, to send video frame data as small as possible to fit within network card buffer frame sizes(and thus fit closer within the internet service provider routing message frames) preventing what we like to call "passing the latency around to the next client", prioritize high fidelity and quality audio streaming, allow clients with constantly interrupted network/internet connection to experience the video stream or more precisely allow the mind to atleast imagine what is going on with minimal delusional ideas if your running a low quality client similar to a radio only experience with visual hints of low quality visual data complementing the stream.
       
         <br/><br/> 
          &nbsp;&nbsp;&nbsp;&nbsp;It should also be noted that this split qualities paradigm works extremely well at taking advantage of custom applications within regards to having access to multi-cast transmision within the service and thus receiving user data grams within the client side programs. This is a speed advantage and also a low latency method of transmitting data, this is due to being able to flag the internet service providers to accept a list of clients to send the same data per one message frame sent from the service that propagates towards the clients with out a dedicated connection, incomparision to TCP, each message frame must have dedicated connection which requires many interconnected bi directional communication amongst the hops inbetween the service and client and thus latency that otherwise would not have existed or would have existed with such a large (however seemingly manageable) size.
      
       <br/><br/> 
       &nbsp;&nbsp;&nbsp;&nbsp;High quality stream will essentialy alert the service not to allocate bi directional communication logic on the server side for each highquality client and likewise the client will not iterate through bi directional communication logic. The service will then send a low quality frame, a medium quality frame and then a high quality frame.    
      <br/><br/> 
       &nbsp;&nbsp;&nbsp;&nbsp;You may wonder why not send the full frame per highquality client, well this allocates time longest towards the clients that will more than likely never experience any interruptions in service; Since services and the users benefit from the video feed being split into pieces based on categories of quality by means of being able to send an entire low quality frame to each client, then send an entire medium quality frame to each client, and then send an entire high quality frame to each client. 
        <br/><br/> 
       &nbsp;&nbsp;&nbsp;&nbsp;A general rule within networking is the smaller the message the higher priority amongst internet service provider routing, low quality frames are usually sent within a few message-frame-buffers with an estimated size of 4096bytes each incomparison to sending a full highquality 720p frame(or a 1080p frame) that will likely dedicate the network to sending an entire one megabyte of data before the next low quality and medium quality frames(and thus latency for each next client). Thus split quality aware protocol provides decreased perceived latency and for the low quality and most of the medium quality clients network latency is decreased.
       <br/><br/> 
       &nbsp;&nbsp;&nbsp;&nbsp;The paradigm of this protocol is also based on sending recognizable data all while reducing file and or ram-memory reads within the computer hardware by focusing on sending one frame to multiple clients and then moving along, with low quality clients prioritized due to their proverbial handicap; 
       <br/><br/> 
       &nbsp;&nbsp;&nbsp;&nbsp;This is forseen as the most efficent and effective way to send data with out relying on formulas to reconstruct the data and effectively accomplishing shasta exchanges mission of delivering the source video quality as accurate as possible and thus the video stream is a more credible source than using compression based video streams all while equally important delivering the most pleasant viewing experience per clients limitations and permanent(or temporary) conditions.
       <br/><br/> 
       
     </div>
     
    
    <div style="margin:3em;"></div> 
    <div style="margin:0.5em;text-align:center; color:#ffffff; font-size:2.5em;">Page created by Shane Bryan Betz</div>
    <div style="margin:6em;"></div>
   </body>
  </html>
